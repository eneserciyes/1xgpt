{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args(arguments):\n",
    "    # parser = argparse.ArgumentParser(description=\"Train a MaskGIT or Llama-style LLM on video generation.\")\n",
    "    parser = argparse.ArgumentParser(description=\"Train a spatial-temporal MaskGIT-style model on video generation.\")\n",
    "\n",
    "    # Data\n",
    "    parser.add_argument(\n",
    "        \"--train_data_dir\", type=str, default=\"data/train_v0.1\",\n",
    "        help=\"Directory containing tokenized data, should have a `video.bin`, `metadata.json` and `segment_ids.json`.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val_data_dir\", type=str, default=\"data/val_v0.1\",\n",
    "        help=\"Directory containing tokenized data, should have a `video.bin`, `metadata.json` and `segment_ids.json`.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--window_size\",\n",
    "        type=int,\n",
    "        default=15,\n",
    "        help=\"Number of frames to in a sequence.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--stride\",\n",
    "        type=int,\n",
    "        default=15,\n",
    "        help=\"Difference in frame count between consecutive frames in a sequence.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--filter_overlaps\",\n",
    "        action=\"store_true\",\n",
    "        help=(\n",
    "            \"Whether to filter repeated frames in the train dataset (`filter_overlaps` always true for the val set). \"\n",
    "            \"Filtering essentially makes the training dataset less correlated but ~16x smaller, \"\n",
    "            \"see the `filter_overlaps` argument in `RawTokenDataset` for details.\")\n",
    "        ,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    parser.add_argument(\n",
    "        \"--llama_config\",\n",
    "        type=str,\n",
    "        help=\"`transformers.LlamaConfig` json. \"\n",
    "             \"E.g. https://huggingface.co/1x-technologies/Llama_1B_v0/blob/main/config.json\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--genie_config\",\n",
    "        type=str,\n",
    "        help=\"GenieConfig json.\"\n",
    "    ),\n",
    "    parser.add_argument(\n",
    "        \"--warmstart_path\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"A path to a checkpoint to warmstart a model from, possibly not trained on the same dataset, \"\n",
    "             \"will resize embeddings if needed.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_from_checkpoint\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"If the training should continue from a checkpoint folder.\",\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    parser.add_argument(\n",
    "        \"--per_device_train_batch_size\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Batch size (per device) for the training dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Batch size (per device) for the evaluation dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_checkpointing\",\n",
    "        default=False,\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        type=float,\n",
    "        default=1e-4,\n",
    "        help=\"Initial learning rate (after the potential warmup period) to use.\",\n",
    "    )\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.0, help=\"Weight decay to use.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", type=int, default=1, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\n",
    "        \"--max_train_steps\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_eval_steps\",\n",
    "        type=int,\n",
    "        default=int(1e10),\n",
    "        help=\"Only evaluate on `max_eval_steps` batches of validation data per process, faster.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_every_n_steps\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Eval every N training steps.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--vis_every_n_steps\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Visualize every N training steps.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_scheduler_type\",\n",
    "        type=str,\n",
    "        default=\"linear\",\n",
    "        help=\"The scheduler type to use.\",\n",
    "        choices=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"custom_cosine\"],\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_warmup_steps\", type=int, default=0, help=\"Number of steps for the warmup in the lr scheduler.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_grad_norm\",\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        help=\"Threshold to clip gradients.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--attention_dropout\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"Attention dropout prob.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_beta_1\",\n",
    "        type=float,\n",
    "        default=0.9,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_beta_2\",\n",
    "        type=float,\n",
    "        default=0.999,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam_eps\",\n",
    "        type=float,\n",
    "        default=1e-8,\n",
    "    )\n",
    "\n",
    "    # Misc\n",
    "    parser.add_argument(\"--output_dir\", type=str, required=True, help=\"Where to store the model checkpoints.\")\n",
    "    parser.add_argument(\n",
    "        \"--checkpointing_steps\",\n",
    "        type=str,\n",
    "        default=\"1000\",\n",
    "        help=\"Whether the various states should be saved at the end of every n steps, or 'epoch' for each epoch.\",\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"A seed for reproducible training.\")\n",
    "    parser.add_argument(\n",
    "        \"--overfit_first_batch\",\n",
    "        action=\"store_true\",\n",
    "        help=(\n",
    "            \"Debug option that trains and validates on only the first batch of the training dataset.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--report_to\",\n",
    "        type=str,\n",
    "        default=\"wandb\",\n",
    "        help=\"The integration to report the results and logs to.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mu_transfer\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If specified, will train with mu transfer reparametrizations. Only supports Llama models.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no_compile\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If specified, will not compile the model.\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(arguments)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENIE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    ")\n",
    "\n",
    "from data import RawTokenDataset, get_maskgit_collator\n",
    "from visualize import decode_latents_wrapper, export_to_gif\n",
    "from genie.config import GenieConfig\n",
    "from genie.st_mask_git import STMaskGIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args([\"--train_data_dir\", \"data/train_v1.1/\", \"--val_data_dir\", \"data/val_v1.1/\", \"--genie_config\", \"genie/configs/magvit_n32_h8_d256.json\", \"--output_dir\", \"data/genie_model\", \"--max_eval_steps\", \"10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RawTokenDataset(args.train_data_dir, window_size=args.window_size,\n",
    "                                stride=args.stride, filter_overlaps=args.filter_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from magvit2/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Restored from data/magvit2.ckpt\n"
     ]
    }
   ],
   "source": [
    "decoded_vid = decode_latents_wrapper(max_images=16)(train_dataset.data[0::args.stride])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_gif(decoded_vid, \"data/decoded_vid.gif\", fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_side_len, vocab_size, hz = [train_dataset.metadata[key] for key in (\"s\", \"vocab_size\", \"hz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GenieConfig.from_pretrained(args.genie_config)\n",
    "config.use_mup = args.mu_transfer  # Note: changing this may affect pre-trained model due to attn scaling\n",
    "config.image_vocab_size = vocab_size\n",
    "config.T = args.window_size\n",
    "config.S = latent_side_len**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STMaskGIT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = default_data_collator if args.llama_config is not None else get_maskgit_collator(config)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=collate_fn,\n",
    "    batch_size=1,# args.per_device_train_batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch = next(iter(train_dataloader))\n",
    "    print(batch['input_ids'][0])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    x = (batch['input_ids'] == batch['labels'])[0]\n",
    "\n",
    "    x = x.reshape(16, 16, 16)\n",
    "\n",
    "\n",
    "    plt.imshow(x[8])\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 13\u001b[0m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m, in \u001b[0;36mstep\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m      6\u001b[0m     batch[key] \u001b[38;5;241m=\u001b[39m batch[key]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniforge3/envs/1x/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def step():\n",
    "    model.train()\n",
    "    model.to(\"cuda\")\n",
    "    batch = next(iter(train_dataloader))\n",
    "    for key in batch:\n",
    "        batch[key] = batch[key].to(\"cuda\")\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "\n",
    "    return loss\n",
    "\n",
    "step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
